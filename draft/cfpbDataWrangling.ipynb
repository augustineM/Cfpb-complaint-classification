{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "The CFPB receives several thousands complaints filed by consumers each year concerning the practices of finanical companies. After reviewing each complaint, the CFPB makes a judgement regarding how the complaint should be resolved. These resolutions historically fall into seven categories with the most punitive being 'closed with monetary relief'.   \n",
    "### Goal\n",
    "The goal of this project is to use This project focuses on predicting consumer complaints received by CFPB.  \n",
    "This section of code is general data wrangling and data management.  The objective of merging files, renaming, and organizing being further exploration and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "This section provides details of the exploratory analysis as well as data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#read saved csv file\n",
    "conComplaintDf=pd.read_csv(\"Consumer_Complaints.csv\",converters={'ZIP code': lambda x: str(x)})\n",
    "\n",
    "#ccDf=conComplaintDf.groupby(['Company response to consumer']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recode the resolutions as integers from 0-8. Recoding should make it easier to explore the data and use with machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#order the responses\n",
    "#0 closed with monetary relief\n",
    "#1 closed with non-monetary relief\n",
    "#2 closed with relief\n",
    "#3 closed with explanation\n",
    "#4 closed\n",
    "#5 closed without relief\n",
    "#6 untimely response\n",
    "#7 in progress\n",
    "conComplaintDf['respCode']=np.where(conComplaintDf['Company response to consumer']== 'Closed with monetary relief',0,\n",
    "    np.where(conComplaintDf['Company response to consumer']== 'Closed with non-monetary relief',1,\n",
    "        np.where(conComplaintDf['Company response to consumer']== 'Closed with relief',2,\n",
    "            np.where(conComplaintDf['Company response to consumer']== 'Closed with explanation',3,\n",
    "                np.where(conComplaintDf['Company response to consumer']== 'Closed',4,\n",
    "                    np.where(conComplaintDf['Company response to consumer']== 'Closed without relief',5,\n",
    "                        np.where(conComplaintDf['Company response to consumer']== 'Untimely response',6,\n",
    "                            np.where(conComplaintDf['Company response to consumer']== 'In progress',7,8))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data received field should be adjusted to a python datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean the date received field\n",
    "#convert 'date received' column from string to datetime\n",
    "#align all complaints to end of month \n",
    "#create a month-year column\n",
    "\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "#conComplaintDfStg['Date received'].dtype\n",
    "conComplaintDf['dateRec']=pd.to_datetime(conComplaintDf['Date received'])#,format='%B/%d/%y')\n",
    "conComplaintDf['adjDate'] = conComplaintDf['dateRec'].map(\n",
    "    lambda x: datetime.datetime(\n",
    "        x.year,\n",
    "        x.month,\n",
    "        max(calendar.monthcalendar(x.year, x.month)[-1][:5])\n",
    "    )\n",
    ")\n",
    "conComplaintDf['monYear']=conComplaintDf['adjDate'].apply(lambda x: x.strftime('%B-%Y'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three response codes(6, 7, 8) that indicate the entire process was not completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop rows without complete information(6&7) create data frames for data analysis\n",
    "\n",
    "#conComplaintDfStg=\n",
    "conComplaintDf.drop(conComplaintDf[conComplaintDf.respCode >=6].index, inplace=True)\n",
    "conComplaintDf['zip3']=conComplaintDf['ZIP code'].str[:3]\n",
    "\n",
    "\n",
    "#create dataframe with complaints resulting in monetary relief\n",
    "#response0Df=conComplaintDf.loc[(conComplaintDf.respCode== 0)]\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded and saved the CFPB complaint database but we could download from the website and load directly into a pandas dataframe.  Below I load census files directly into pandas dataframes from their host websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download urban area to cbsa file\n",
    "#UA:urban area number\n",
    "#UANAME: urban area name\n",
    "#CBSA: corebased statistical area number(micro/metropolitan statistical area)\n",
    "#MNAME: cbsa name\n",
    "#MEMI: 1=metropolitan statistical area; 2=micropolitan statistical area\n",
    "url=\"https://www2.census.gov/geo/docs/maps-data/data/rel/ua_cbsa_rel_10.txt\"\n",
    "uaToCbsaDf=pd.read_csv(url,encoding='latin1')#converters={'ZCTA5': lambda x: str(x)})\n",
    "uaToCbsaDf=uaToCbsaDf[['UA','UANAME','CBSA','MNAME','MEMI','POPPT']]\n",
    "uaToCbsaDf.drop(uaToCbsaDf[(uaToCbsaDf.MEMI != 1) | (uaToCbsaDf.UA== 99999)|(uaToCbsaDf.CBSA==99999) ].index, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download zip to cbsa file\n",
    "\n",
    "import urllib.request\n",
    "import requests\n",
    "import io\n",
    "url=\"https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_cbsa_rel_10.txt\"\n",
    "#zipToSaDf=pd.read_csv(url,'ZCTA5',index_col=0)\n",
    "#preserve leading zeros in zip5\n",
    "zipToSaDf=pd.read_csv(url,converters={'ZCTA5': lambda x: str(x)})\n",
    "zipToSaDf=zipToSaDf[['ZCTA5','CBSA','ZPOP','MEMI']]\n",
    "zipToSaDf.drop(zipToSaDf[(zipToSaDf.MEMI)!=1].index,inplace=True)\n",
    "zipToSaDf['zip3']=zipToSaDf.ZCTA5.str[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some records contain zip5 and some contain zip3.  This causes problems when merging\n",
    "#I will split the cfpb data into two files\n",
    "#1- with full 5-digit zip code\n",
    "#2- with 3-digit zip code\n",
    "conComplaintZ5=conComplaintDf[conComplaintDf['ZIP code'].str.contains(\"XX\")==False]\n",
    "\n",
    "conComplaintZ3=conComplaintDf[conComplaintDf['ZIP code'].str.contains(\"XX\")==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#later we will use zip codes to merge with census files(urban area and msa)\n",
    "#since zip3 is truncated zip5, they may link with multiple zip5s and UA/MSA\n",
    "#I want to remove the smaller(by population) instances of zip3\n",
    "#sort by zip3 and zip-level population\n",
    "#goal is to keep zip3 with largest population \n",
    "zipToSaDf.sort_values(['zip3','ZPOP'])\n",
    "zipToSaDfZ3=zipToSaDf.drop_duplicates(['zip3'],keep='last')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are focused on merging the census files to create a normalized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the zip To CBSA file onto the split(by zip3 and zip5) consumer complaint data\n",
    "cfpbComplaintCbsaZ5= pd.merge(conComplaintZ5,zipToSaDf,left_on=['ZIP code','zip3'],right_on=['ZCTA5','zip3'],how='left')\n",
    "cfpbComplaintCbsaZ3= pd.merge(conComplaintZ3,zipToSaDfZ3,on=['zip3'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenate the zip5 and zip3 files\n",
    "cfpbComplaintCbsa= pd.concat([cfpbComplaintCbsaZ5,cfpbComplaintCbsaZ3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since UA to CBSA is a 'one to many' relationship, I'm going to keep the CBSA with largest population for this exercise.  The idea, is that there is a greater probability of the consumer residing in the CBSA with a larger population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uaToCbsaDf.sort_values(['CBSA','POPPT'],inplace=True)\n",
    "uaToCbsaDf=uaToCbsaDf.drop_duplicates(['CBSA'],keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to change the data type from float to int for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfpbComplaintCbsa['CBSA']=cfpbComplaintCbsa['CBSA'].fillna(0.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now merge with the uaCbsa data to add urban area information\n",
    "cfpbComplaintCbsaUa=pd.merge(cfpbComplaintCbsa,uaToCbsaDf, on='CBSA', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading a zip file and loading into pandas is a bit different (and not as straight forward) than what I did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen   \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "URL = \\\n",
    "    'http://www2.census.gov/geo/docs/maps-data/data/gazetteer/Gaz_ua.zip'\n",
    "\n",
    "# open and save the zip file onto computer\n",
    "url = urlopen(URL)\n",
    "output = open('zipFile.zip', 'wb')    # note the flag:  \"wb\"        \n",
    "output.write(url.read())\n",
    "output.close()\n",
    "\n",
    "# read the zip file as a pandas dataframe\n",
    "uaGaz = pd.read_csv('zipFile.zip',sep='\\t',encoding='latin1')   # pandas version 0.18.1 takes zip files       \n",
    "\n",
    "# if keeping on disk the zip file is not wanted, then:\n",
    "#os.remove(zipName)   # remove the copy of the zipfile on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep ID, Lat, Long fields and merge onto cfpb data\n",
    "#uaGaz.count()\n",
    "#uaGaz=uaGaz[['GEOID','INTPTLAT','INTPTLONG']]\n",
    "gazCols=['GEOID','NAME',\n",
    " 'UATYPE',\n",
    " 'POP10',\n",
    " 'HU10',\n",
    " 'ALAND',\n",
    " 'AWATER',\n",
    " 'ALAND_SQMI',\n",
    " 'AWATER_SQMI',\n",
    " 'INTPTLAT',\n",
    " 'INTPTLONG']\n",
    "uaGaz.columns=gazCols\n",
    "cfpbComplaintCbsaUaLl= pd.merge(cfpbComplaintCbsaUa,uaGaz,left_on='UA',right_on='GEOID',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfpbComplaintCbsaUaLl.iloc[:,-1]\n",
    "cfpbComplaintCbsaUaLl.rename(columns={'INTPTLONG\\n':'INTPTLONG'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfpbComplaintCbsaUaLl['target']=np.where(cfpbComplaintCbsaUaLl['respCode']== 0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I take care of missing values and recode categorical values into binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Text processing replace na with an empty string\n",
    "cfpbComplaintCbsaUaLl['Consumer complaint narrative']= cfpbComplaintCbsaUaLl['Consumer complaint narrative'].fillna('')\n",
    "cfpbComplaintCbsaUaLl['State']= cfpbComplaintCbsaUaLl['State'].fillna('')\n",
    "#transform categorical variables into binary\n",
    "cfpbComplaintCbsaUaLl['UA']=cfpbComplaintCbsaUaLl['UA'].astype('category')\n",
    "#catCols= ['State','Product','Issue','UA']\n",
    "catCols= ['Product','Issue','UA']\n",
    "dfDummies= pd.get_dummies(cfpbComplaintCbsaUaLl[catCols])\n",
    "dataStg= pd.concat([cfpbComplaintCbsaUaLl,dfDummies],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to split the data into train and test sets (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train/test splitting\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#split dataStg into train/ test\n",
    "train, test= train_test_split(dataStg,test_size=.2)\n",
    "\n",
    "# recreate index in test and train sets so we can run through the text processing function\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
